{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a Multi-Object Tracking Model on MOT Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to evaluate [FairMOT](https://github.com/ifzhang/FairMOT) with [MOT Challenge dataset](https://motchallenge.net/). It hosts the most common benchmarking datasets for pedestrian MOT. Different datasets exist: MOT15, MOT16/17, MOT 19/20. These datasets contain many video sequences, with different tracking difficulty levels, with annotated ground-truth. Detections are also provided for optional use by the participating tracking algorithms.\n",
    "\n",
    "The goals of this notebook are:\n",
    "* Show the advantages of FairMOT on standardized metrics\n",
    "* Easy to compare with other state of the art MOT trackers\n",
    "* Re-produce the results on public dataset - MOT Challenge, contributes to larger research community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchVision: 0.4.0a0+6b959ee\n",
      "Torch is using GPU: Tesla K80\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "from ipywidgets import Video\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from utils_cv.tracking.data import Urls\n",
    "from utils_cv.tracking.dataset import TrackingDataset\n",
    "from utils_cv.tracking.model import TrackingLearner, write_video\n",
    "\n",
    "from utils_cv.common.data import data_path, download, unzip_url\n",
    "from utils_cv.common.gpu import which_processor, is_windows\n",
    "\n",
    "# Change matplotlib backend so that plots are shown for windows\n",
    "if is_windows():\n",
    "    plt.switch_backend(\"TkAgg\")\n",
    "\n",
    "print(f\"TorchVision: {torchvision.__version__}\")\n",
    "which_processor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows your machine's GPUs (if it has any) and the computing device `torch/torchvision` is using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure edits to libraries are loaded and plotting is shown in the notebook.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set some model runtime parameters. We evaluate the FairMOT model on MOT17 or MOT16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch device: cuda\n"
     ]
    }
   ],
   "source": [
    "CONF_THRES = 0.3\n",
    "TRACK_BUFFER = 300\n",
    "IM_SIZE = (1080, 1920)\n",
    "\n",
    "# Evaluate on MOT17 or MOT16\n",
    "MOT16_or_17 = \"MOT17\"\n",
    "# Downloaded MOT Challendage data path\n",
    "MOT_SAVED_PATH = \"../../data/\"\n",
    "RESEULT_ROOT = \"./results\"\n",
    "EXP_NAME = \"MOT_val_all_dla34\"\n",
    "\n",
    "FT_MODEL = \"./models/all_dla34.pth\"\n",
    "\n",
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using torch device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01  Pretrained Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [MOT17](https://motchallenge.net/data/MOT17.zip) or [MOT16](https://motchallenge.net/data/MOT16.zip) data to the path `MOT_SAVED_PATH`. The MOT17 dataset is around 5G and MOT16 is around 2G. May take some time to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/MOT17/train\n"
     ]
    }
   ],
   "source": [
    "base = \"https://motchallenge.net/data/\"\n",
    "if MOT16_or_17 == \"MOT17\":\n",
    "    mot_path = urljoin(base, \"MOT17.zip\")\n",
    "    MOT_SAVED_PATH = os.path.join(MOT_SAVED_PATH, \"MOT17\", \"train\")\n",
    "    seqs_str = '''MOT17-02-SDP\n",
    "                      MOT17-04-SDP\n",
    "                      MOT17-05-SDP\n",
    "                      MOT17-09-SDP\n",
    "                      MOT17-10-SDP\n",
    "                      MOT17-11-SDP\n",
    "                      MOT17-13-SDP'''\n",
    "elif MOT16_or_17 == \"MOT16\":\n",
    "    mot_path = urljoin(base, \"MOT16.zip\")\n",
    "    MOT_SAVED_PATH = os.path.join(MOT_SAVED_PATH, \"MOT16\", \"train\")\n",
    "    seqs_str = '''MOT16-02\n",
    "                      MOT16-04\n",
    "                      MOT16-05\n",
    "                      MOT16-09\n",
    "                      MOT16-10\n",
    "                      MOT16-11\n",
    "                      MOT16-13'''\n",
    "unzip_url(mot_path, dest=MOT_SAVED_PATH, exist_ok=True)\n",
    "print(MOT_SAVED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and load the model. We use the pre-trained baseline FairMOT model - `all_dla34.pth`, which can be downloaded [here](https://drive.google.com/file/d/1udpOPum8fJdoEQm6n0jsIgMMViOMFinu/view). Please upload and save `all_dla34.pth` to `FT_MODEL` path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <class 'utils_cv.tracking.references.fairmot.models.networks.pose_dla_dcn.DLASeg'>\n"
     ]
    }
   ],
   "source": [
    "tracker = TrackingLearner(None, FT_MODEL)\n",
    "print(f\"Model: {type(tracker.model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`eval_mot` function calls the prediction function, saves the tracking results to txt file and provides the evaluation results with [motmetrics](https://github.com/cheind/py-motmetrics) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mot(conf_thres, track_buffer, im_size, data_root, seqs, result_root, exp_name, run_eval=False):\n",
    "    eval_result = os.path.join(result_root, exp_name)\n",
    "    if not osp.exists(eval_result):\n",
    "        os.makedirs(eval_result)\n",
    "    accs = []\n",
    "    n_frame = 0\n",
    "    timer_avgs, timer_calls = [], []\n",
    "    for seq in seqs:\n",
    "        print('start seq: {}'.format(seq))\n",
    "        im_or_video_path = osp.join(data_root, seq, 'img1')\n",
    "        result_filename = '{}.txt'.format(seq)\n",
    "        result_file_path = os.path.join(result_root, exp_name, result_filename)\n",
    "        meta_info = open(os.path.join(data_root, seq, 'seqinfo.ini')).read()\n",
    "        frame_rate = int(meta_info[meta_info.find('frameRate') + 10:meta_info.find('\\nseqLength')])\n",
    "        # If prediction results file doesn't exsit or run_eval = True, will re-run the inference.\n",
    "        if not osp.exists(result_file_path) or run_eval:\n",
    "            # Run tracking.\n",
    "            eval_results = tracker.predict(\n",
    "                im_or_video_path,\n",
    "                conf_thres,\n",
    "                track_buffer,\n",
    "                im_size,\n",
    "                frame_rate)\n",
    "            result_file_path = tracker.savetxt_results(eval_results, exp_name, result_root, result_filename, if_tmp=False)\n",
    "            print(\"Re-run the inference, saved in path \", result_file_path)\n",
    "        print(\"Saved tracking result txt path: \", result_file_path)\n",
    "        # eval\n",
    "        print('Evaluate seq: {}'.format(seq))\n",
    "        mot_accumulator = tracker.evaluate_mot(data_root, seq, result_file_path)\n",
    "        accs.append(mot_accumulator)\n",
    "    strsummary = tracker.mot_summary(accs, seqs)\n",
    "    return strsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use training dataset from MOT17 or MOT16 to evaluate with the ground truth. The following evaluation results on MOT Challenge training set are comparable with the [FairMOT paper](https://arxiv.org/abs/2004.01888) reported on MOT Challenge test set:\n",
    "\n",
    "| Dataset | MOTA   | IDF1 | IDS | MT | ML | FPS |\n",
    "|------|------|------|------|------|------|------|\n",
    "|   MOT16  | 68.7| 70.4| 953| 39.5%| 19.0%| 25.9|\n",
    "|   MOT17  | 67.5| 69.8| 2868| 37.7%| 20.8%| 25.9|\n",
    "\n",
    "For evaluating on testing dataset, you can get the txt prediction results in this section and submit to the [MOT Challenge](https://motchallenge.net/) evaluation server to obtain the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on MOT17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start seq: MOT17-02-SDP\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT17-02-SDP.txt\n",
      "Evaluate seq: MOT17-02-SDP\n",
      "start seq: MOT17-04-SDP\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT17-04-SDP.txt\n",
      "Evaluate seq: MOT17-04-SDP\n",
      "start seq: MOT17-05-SDP\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT17-05-SDP.txt\n",
      "Evaluate seq: MOT17-05-SDP\n",
      "start seq: MOT17-09-SDP\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT17-09-SDP.txt\n",
      "Evaluate seq: MOT17-09-SDP\n",
      "start seq: MOT17-10-SDP\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT17-10-SDP.txt\n",
      "Evaluate seq: MOT17-10-SDP\n",
      "start seq: MOT17-11-SDP\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT17-11-SDP.txt\n",
      "Evaluate seq: MOT17-11-SDP\n",
      "start seq: MOT17-13-SDP\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT17-13-SDP.txt\n",
      "Evaluate seq: MOT17-13-SDP\n",
      "              IDF1   IDP   IDR  Rcll  Prcn  GT  MT  PT ML    FP    FN IDs    FM  MOTA  MOTP IDt IDa IDm\n",
      "MOT17-02-SDP 60.1% 68.9% 53.3% 72.3% 93.4%  62  28  25  9   950  5148 243   628 65.9% 0.198 138  49  16\n",
      "MOT17-04-SDP 83.2% 85.1% 81.2% 86.3% 90.4%  83  51  21 11  4348  6526  32   219 77.1% 0.172   6  20   1\n",
      "MOT17-05-SDP 73.1% 75.5% 70.9% 83.9% 89.2% 133  74  50  9   702  1117 120   217 72.0% 0.221 100  45  41\n",
      "MOT17-09-SDP 65.9% 71.6% 61.0% 81.5% 95.7%  26  18   8  0   197   984  45   105 77.0% 0.175  34  10   7\n",
      "MOT17-10-SDP 63.5% 68.4% 59.2% 79.0% 91.3%  57  30  27  0   970  2700 182   439 70.0% 0.233 109  44  14\n",
      "MOT17-11-SDP 82.2% 82.0% 82.4% 92.3% 91.9%  75  55  16  4   764   722  75   112 83.5% 0.171  29  34   9\n",
      "MOT17-13-SDP 64.6% 65.9% 63.3% 77.2% 80.3% 110  50  51  9  2203  2658 164   457 56.8% 0.279  97  39  42\n",
      "OVERALL      73.9% 77.5% 70.7% 82.3% 90.1% 546 306 198 42 10134 19855 861  2177 72.5% 0.196 513 241 130\n"
     ]
    }
   ],
   "source": [
    "seqs = [seq.strip() for seq in seqs_str.split()]\n",
    "\n",
    "# run_eval: if need to re-run the prediction\n",
    "strsummary = eval_mot(conf_thres=CONF_THRES,\n",
    "             track_buffer=TRACK_BUFFER,\n",
    "             im_size=IM_SIZE,\n",
    "             data_root=MOT_SAVED_PATH,\n",
    "             seqs=seqs,\n",
    "             result_root = RESEULT_ROOT,\n",
    "             exp_name = EXP_NAME,\n",
    "             run_eval = False)\n",
    "print(strsummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change MOT16_or_17 = \"MOT16\". Re-run the notebook and evaluate on MOT16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start seq: MOT16-02\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT16-02.txt\n",
      "Evaluate seq: MOT16-02\n",
      "start seq: MOT16-04\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT16-04.txt\n",
      "Evaluate seq: MOT16-04\n",
      "start seq: MOT16-05\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT16-05.txt\n",
      "Evaluate seq: MOT16-05\n",
      "start seq: MOT16-09\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT16-09.txt\n",
      "Evaluate seq: MOT16-09\n",
      "start seq: MOT16-10\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT16-10.txt\n",
      "Evaluate seq: MOT16-10\n",
      "start seq: MOT16-11\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT16-11.txt\n",
      "Evaluate seq: MOT16-11\n",
      "start seq: MOT16-13\n",
      "Saved tracking result txt path:  ./results/MOT_val_all_dla34/MOT16-13.txt\n",
      "Evaluate seq: MOT16-13\n",
      "          IDF1   IDP   IDR  Rcll  Prcn  GT  MT  PT ML    FP    FN IDs    FM  MOTA  MOTP IDt IDa IDm\n",
      "MOT16-02 60.1% 67.3% 54.3% 73.6% 91.3%  54  26  24  4  1252  4702 239   590 65.3% 0.197 126  47  12\n",
      "MOT16-04 83.2% 85.1% 81.2% 86.3% 90.4%  83  51  21 11  4348  6526  32   219 77.1% 0.172   6  20   1\n",
      "MOT16-05 72.6% 74.4% 70.9% 83.9% 88.0% 125  70  48  7   778  1095 122   212 70.7% 0.222  98  48  42\n",
      "MOT16-09 66.2% 71.4% 61.7% 81.6% 94.5%  25  17   8  0   249   968  45   104 76.0% 0.176  33  10   6\n",
      "MOT16-10 62.9% 66.3% 59.8% 79.0% 87.6%  54  27  27  0  1380  2589 162   412 66.5% 0.233 101  38  13\n",
      "MOT16-11 82.0% 80.7% 83.3% 92.5% 89.5%  69  51  16  2   992   687  67   103 81.0% 0.169  25  30   8\n",
      "MOT16-13 64.5% 65.3% 63.8% 77.2% 79.0% 107  50  49  8  2348  2609 164   451 55.3% 0.279  95  39  40\n",
      "OVERALL  73.9% 76.7% 71.3% 82.6% 88.9% 517 292 193 32 11347 19176 831  2091 71.6% 0.196 484 232 122\n"
     ]
    }
   ],
   "source": [
    "seqs = [seq.strip() for seq in seqs_str.split()]\n",
    "\n",
    "# run_eval: if need to re-run the prediction\n",
    "strsummary = eval_mot(conf_thres=CONF_THRES,\n",
    "             track_buffer=TRACK_BUFFER,\n",
    "             im_size=IM_SIZE,\n",
    "             data_root=MOT_SAVED_PATH,\n",
    "             seqs=seqs,\n",
    "             result_root = RESEULT_ROOT,\n",
    "             exp_name = EXP_NAME,\n",
    "             run_eval = False)\n",
    "print(strsummary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "356.263px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
